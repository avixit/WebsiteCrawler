<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-dark.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <title>Websitecrawler by avixit</title>
  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1>Websitecrawler</h1>
          <h2>Website/URL crawler based on DOM Parsing in Java</h2>
        </header>

        <section id="downloads" class="clearfix">
          <a href="https://github.com/avixit/WebsiteCrawler/zipball/master" id="download-zip" class="button"><span>Download .zip</span></a>
          <a href="https://github.com/avixit/WebsiteCrawler/tarball/master" id="download-tar-gz" class="button"><span>Download .tar.gz</span></a>
          <a href="https://github.com/avixit/WebsiteCrawler" id="view-on-github" class="button"><span>View on GitHub</span></a>
        </section>

        <hr>

        <section id="main_content">
          <h1>
<a id="websitecrawler" class="anchor" href="#websitecrawler" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>WebsiteCrawler</h1>

<p>This is a website crawler based on DOM Parsing in Java. You may configure it in your eclipse as well.</p>

<p>Thanks to Jodd for the amazing set of Java micro frameworks, tools and utilities. (<a href="http://jodd.org/">http://jodd.org/</a>)</p>

<p><b>Prerequisites : <br></b>
1) Minimum Java 8 is required to run this. Please download latest version of Java from <a href="https://www.java.com/">here</a></p>

<p><b>Features :<br></b>
1) Crawl your URL using command line. Multiple command line arguments are available to use. <br>
2) Automatically filters external links and popular file formats like jpg, png, gif, js and pdf. <br>
3) Either display the crawling results in console or save it to HTML file for future reference. <br></p>

<p><b>Usage : <br></b>
1) Configure the new project in Eclipse. You will need to add the dependency of "lib/jodd-all-3.8.0.jar" file in your build path. <br>
2) Compile and run the "WebsiteURLCrawler.java/class" file with appropriate command line arguments.<br>
3) Currently it will filter following type of data : External URL, PDF, JPG/JPEG, PNG and GIF. <br>
4) Sample jar file from the latest build and a HTML file that contains crawling results from popular online coding website <a href="https://www.hackerrank.com">hackerrank</a> is added in repo as WebsiteCrawler/sample/WebsiteCrawler.jar. Hit "<b>java -jar WebsiteCrawler.jar -help</b>" to see all available options. <br>
5) Should you need any help in using/configuring or you have any suggestions or improvements or want to contribute, please shoot me an email (<a href="mailto:avixit.aparnathi@gmail.com">avixit.aparnathi@gmail.com</a>) with all the details. I shall definitely get back to you. <br></p>

<p><b>Future Enhancements : <br></b>
1) Add cookie support to fetch all the url's after login in a website. <br>
2) Add support to save the crawling result in multiple file formats (i.e text, XLS, PDF etc). <br>
3) Add dynamic filtering (i.e If you want only images or PDF or any specific type of files from a website). <br>
4) Add E-mail Id and mobile number filters. <br></p>

<p>Happy Crawling !</p>
        </section>

        <footer>
          Websitecrawler is maintained by <a href="https://github.com/avixit">avixit</a><br>
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a>. Tactile theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.
        </footer>

        
      </div>
    </div>
  </body>
</html>
